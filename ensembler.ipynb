{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_visible_with_infrared(visible_img, infrared_img):\n",
    "\n",
    "    visible_lab = cv2.cvtColor(visible_img, cv2.COLOR_BGR2LAB)\n",
    "    infrared_img = cv2.resize(infrared_img, (visible_img.shape[1], visible_img.shape[0]))\n",
    "\n",
    "    # Extract the L channel from the LAB color space\n",
    "    l_channel = visible_lab[:, :, 0]\n",
    "\n",
    "    # Enhance the L channel using the infrared image\n",
    "    enhanced_l_channel = cv2.addWeighted(l_channel, 0.5, infrared_img, 0.5, 0)\n",
    "\n",
    "    # Replace the original L channel with the enhanced one\n",
    "    visible_lab[:, :, 0] = enhanced_l_channel\n",
    "\n",
    "    # Convert the enhanced LAB image back to BGR color space\n",
    "    enhanced_visible_img = cv2.cvtColor(visible_lab, cv2.COLOR_LAB2BGR)\n",
    "    cv2.imwrite('images/enhanced_visible.jpg', enhanced_visible_img)\n",
    "    \n",
    "    return enhanced_visible_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # denoise the image\n",
    "    img = cv2.fastNlMeansDenoisingColored(img, None, 1, 1, 5, 21)\n",
    "    \n",
    "    # Convert the image from BGR color space to LAB color space\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
    "    \n",
    "    # Split the LAB image into L, A and B channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # Apply CLAHE to L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    \n",
    "    # Merge the CLAHE enhanced L channel with the original A and B channel\n",
    "    enhanced_lab = cv2.merge((cl,a,b))\n",
    "    \n",
    "    # Convert the image back to BGR format\n",
    "    img = cv2.cvtColor(enhanced_lab, cv2.COLOR_Lab2BGR)\n",
    "    \n",
    "    cv2.imwrite('images/processed_image.jpg', img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "visible_model = YOLO('models/visible.pt')\n",
    "thermal_model = YOLO('models/thermal.pt')\n",
    "\n",
    "infrared_img = cv2.imread(\"images/infrared.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "visible_img = cv2.imread(\"images/visible.jpg\")\n",
    "thermal_img = cv2.imread(\"images/thermal.jpg\")\n",
    "\n",
    "visible_img = enhance_visible_with_infrared(visible_img,infrared_img)\n",
    "visible_img = preprocess_img(visible_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ NMS time limit 0.550s exceeded\n",
      "0: 480x640 12 persons, 2 bicycles, 1 motorcycle, 1 bench, 4 umbrellas, 1 chair, 352.1ms\n",
      "Speed: 6.0ms preprocess, 352.1ms inference, 1573.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mD:\\softwares\\vscode\\python\\ensembledmodel\\runs\\detect\\predict55\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 336.6ms\n",
      "Speed: 2.0ms preprocess, 336.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mD:\\softwares\\vscode\\python\\ensembledmodel\\runs\\detect\\predict56\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results_visible = visible_model.predict(source=visible_img, save=True)\n",
    "results_thermal = thermal_model.predict(source=thermal_img, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of detections in thermal = 0\n",
      "number of detections in visible = 21\n"
     ]
    }
   ],
   "source": [
    "print(\"number of detections in thermal = \" + str(len(results_thermal[0].boxes)))\n",
    "print(\"number of detections in visible = \" + str(len(results_visible[0].boxes)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_list = []\n",
    "scores_list = []\n",
    "labels_list = []\n",
    "\n",
    "# bicycle in infra = 0 change it to 1\n",
    "# car in infra = 1 change it to 2\n",
    "# person in infra = 2 change it to 0\n",
    "\n",
    "# bicycle in thermal = 0 change it to 1\n",
    "# car in thermal = 1 change it 2\n",
    "# person in thermal = 3 change it to 0\n",
    "# dog in thermal = 2 change it to 17 \n",
    "\n",
    "def relabel(model,c):\n",
    "    if(model == 'visible'):\n",
    "        if(c == 7): return 2\n",
    "        return c\n",
    "    if(model == 'infrared'):\n",
    "        if(c == 0): return 1\n",
    "        if(c == 1): return 2\n",
    "        if(c == 2): return 0\n",
    "        \n",
    "    if(c == 0): return 1\n",
    "    if(c == 1): return 2\n",
    "    if(c == 3): return 0\n",
    "    if(c == 2): return 17\n",
    "   \n",
    "def combine_result(result,model = 'visible'):\n",
    "    cur_boxes_list = []\n",
    "    cur_scores_list = []\n",
    "    cur_labels_list = []\n",
    "    \n",
    "    for r in result:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:   \n",
    "            b = box.xyxy[0] \n",
    "            c = box.cls\n",
    "            score = box.conf\n",
    "            if(score > 0.3):\n",
    "                cur_boxes_list.append(b)\n",
    "                cur_scores_list.append(score)\n",
    "                cur_labels_list.append(relabel(model,c))\n",
    "                \n",
    "    boxes_list.append(cur_boxes_list)\n",
    "    scores_list.append(cur_scores_list)\n",
    "    labels_list.append(cur_labels_list)\n",
    "    \n",
    "combine_result(results_thermal,'thermal')\n",
    "combine_result(results_visible)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([7.1144e-02, 1.6232e+02, 3.6668e+01, 2.3969e+02]), tensor([193.6515, 112.7302, 213.1233, 176.4601]), tensor([271.1494, 112.9939, 308.6399, 201.9917]), tensor([2.6978e-02, 1.3226e+02, 3.0321e+01, 1.7920e+02]), tensor([121.3488, 137.1816, 151.6475, 198.5643]), tensor([ 83.4306, 134.1086, 110.8255, 191.0008]), tensor([220.6516, 115.1308, 233.8808, 156.9962]), tensor([156.2414, 108.9907, 177.3053, 116.3447]), tensor([176.8253, 111.7766, 191.1967, 117.5332]), tensor([ 56.1848, 127.5705,  88.3339, 166.0059]), tensor([166.1029, 115.8994, 174.7498, 129.5180]), tensor([177.8506, 115.2158, 186.7646, 139.9413]), tensor([108.0314, 102.6780, 149.1077, 114.6645]), tensor([ 86.0397, 113.3627,  99.1617, 134.6866]), tensor([120.6128, 114.8236, 156.2406, 182.9259]), tensor([ 50.2323, 140.8474,  86.4843, 192.4600]), tensor([157.6383, 116.0931, 166.6913, 135.9849])]\n"
     ]
    }
   ],
   "source": [
    "print(boxes_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefilter_boxes(boxes, scores, labels, weights, thr):\n",
    " \n",
    "    new_boxes = dict()\n",
    "\n",
    "    for t in range(len(boxes)):\n",
    "\n",
    "        if len(boxes[t]) != len(scores[t]):\n",
    "            print('Error. Length of boxes arrays not equal to length of scores array: {} != {}'.format(len(boxes[t]), len(scores[t])))\n",
    "            exit()\n",
    "\n",
    "        if len(boxes[t]) != len(labels[t]):\n",
    "            print('Error. Length of boxes arrays not equal to length of labels array: {} != {}'.format(len(boxes[t]), len(labels[t])))\n",
    "            exit()\n",
    "\n",
    "        for j in range(len(boxes[t])):\n",
    "            score = scores[t][j]\n",
    "            if score < thr:\n",
    "                continue\n",
    "            label = int(labels[t][j])\n",
    "            box_part = boxes[t][j]\n",
    "            x1 = float(box_part[0])\n",
    "            y1 = float(box_part[1])\n",
    "            x2 = float(box_part[2])\n",
    "            y2 = float(box_part[3])\n",
    "          \n",
    "            b = [int(label), float(score) * weights[t], weights[t], t, x1, y1, x2, y2]\n",
    "            if label not in new_boxes:\n",
    "                new_boxes[label] = []\n",
    "            new_boxes[label].append(b)\n",
    "\n",
    "    for k in new_boxes:\n",
    "        current_boxes = np.array(new_boxes[k])\n",
    "        new_boxes[k] = current_boxes[current_boxes[:, 1].argsort()[::-1]]\n",
    "\n",
    "    return new_boxes\n",
    "\n",
    "\n",
    "def get_weighted_box(boxes, conf_type):\n",
    "\n",
    "    box = np.zeros(8, dtype=np.float32)\n",
    "    conf = 0\n",
    "    conf_list = []\n",
    "    w = 0\n",
    "    for b in boxes:\n",
    "        box[4:] += (b[1] * b[4:])\n",
    "        conf += b[1]\n",
    "        conf_list.append(b[1])\n",
    "        w += b[2]\n",
    "    box[0] = boxes[0][0]\n",
    "    box[1] = np.array(conf_list).max()\n",
    "    box[2] = w\n",
    "    box[3] = -1 \n",
    "    box[4:] /= conf\n",
    "    return box\n",
    "\n",
    "\n",
    "def find_matching_box_fast(boxes_list, new_box, match_iou):\n",
    "\n",
    "    def bb_iou_array(boxes, new_box):\n",
    "        # bb interesection over union\n",
    "        xA = np.maximum(boxes[:, 0], new_box[0])\n",
    "        yA = np.maximum(boxes[:, 1], new_box[1])\n",
    "        xB = np.minimum(boxes[:, 2], new_box[2])\n",
    "        yB = np.minimum(boxes[:, 3], new_box[3])\n",
    "\n",
    "        interArea = np.maximum(xB - xA, 0) * np.maximum(yB - yA, 0)\n",
    "\n",
    "        # compute the area of both the prediction and ground-truth rectangles\n",
    "        boxAArea = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "        boxBArea = (new_box[2] - new_box[0]) * (new_box[3] - new_box[1])\n",
    "\n",
    "        iou = interArea / (boxAArea + boxBArea - interArea)\n",
    "\n",
    "        return iou\n",
    "\n",
    "    if boxes_list.shape[0] == 0:\n",
    "        return -1, match_iou\n",
    "\n",
    "    # boxes = np.array(boxes_list)\n",
    "    boxes = boxes_list\n",
    "\n",
    "    ious = bb_iou_array(boxes[:, 4:], new_box[4:])\n",
    "\n",
    "    ious[boxes[:, 0] != new_box[0]] = -1\n",
    "\n",
    "    best_idx = np.argmax(ious)\n",
    "    best_iou = ious[best_idx]\n",
    "\n",
    "    if best_iou <= match_iou:\n",
    "        best_iou = match_iou\n",
    "        best_idx = -1\n",
    "\n",
    "    return best_idx, best_iou\n",
    "\n",
    "\n",
    "def weighted_boxes_fusion(\n",
    "        boxes_list,\n",
    "        scores_list,\n",
    "        labels_list,\n",
    "        weights=None,\n",
    "        iou_thr=0.1,\n",
    "        skip_box_thr=0.3,\n",
    "        conf_type='max',\n",
    "        allows_overflow=False\n",
    "):\n",
    "\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(boxes_list))\n",
    "    \n",
    "    weights = np.array(weights)\n",
    "\n",
    "    filtered_boxes = prefilter_boxes(boxes_list, scores_list, labels_list, weights, skip_box_thr)\n",
    "    if len(filtered_boxes) == 0:\n",
    "        return np.zeros((0, 4)), np.zeros((0,)), np.zeros((0,))\n",
    "\n",
    "    overall_boxes = []\n",
    "    for label in filtered_boxes:\n",
    "        boxes = filtered_boxes[label]\n",
    "        new_boxes = []\n",
    "        weighted_boxes = np.empty((0, 8))\n",
    "\n",
    "        # Clusterize boxes\n",
    "        for j in range(0, len(boxes)):\n",
    "            index, best_iou = find_matching_box_fast(weighted_boxes, boxes[j], iou_thr)\n",
    "            if index != -1:\n",
    "                boxes[index][1] = np.minimum(boxes[index][1] * 1.15 * boxes[j][2],0.99)\n",
    "                new_boxes[index].append(boxes[index])\n",
    "                weighted_boxes[index] = get_weighted_box(new_boxes[index], conf_type)\n",
    "            else:\n",
    "                new_boxes.append([boxes[j].copy()])\n",
    "                weighted_boxes = np.vstack((weighted_boxes, boxes[j].copy()))\n",
    "\n",
    "        # Rescale confidence based on number of models and boxes\n",
    "        for i in range(len(new_boxes)):\n",
    "            weighted_boxes[i, 1] = weighted_boxes[i, 1] / weights.max()\n",
    "            \n",
    "        overall_boxes.append(weighted_boxes)\n",
    "    overall_boxes = np.concatenate(overall_boxes, axis=0)\n",
    "    overall_boxes = overall_boxes[overall_boxes[:, 1].argsort()[::-1]]\n",
    "    boxes = overall_boxes[:, 4:]\n",
    "    scores = overall_boxes[:, 1]\n",
    "    labels = overall_boxes[:, 0]\n",
    "    return boxes, scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "boxes,scores,labels = weighted_boxes_fusion(boxes_list,scores_list,labels_list)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9926300048828125\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "print(execution_time * 1000)\n",
    "print(len(boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(0, 255, 0), (0, 0, 255), (0, 255, 255)]  # Green, Red, yellow\n",
    "final_image_choice = \"visible\"\n",
    "image = cv2.imread('images/'+ final_image_choice + '.jpg')\n",
    "\n",
    "for i in range(scores.size):\n",
    "    box = boxes[i].astype(np.int32)\n",
    "    label = labels[i]\n",
    "    score = scores[i]\n",
    "    cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), colors[int(label % len(colors))], 2)\n",
    "    label_text = f'{label}: {score:.2f}'\n",
    "    cv2.putText(image, label_text, (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[int(label % len(colors))], 2)\n",
    "    \n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite('final_image.jpg', image)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
